{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f637bf-b5d7-49f6-9ab5-87b7bdbe5253",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Merging Data ---\n",
      "Columns in df_cc: ['ID', 'cc_cons']\n",
      "Renamed 'ID' to 'Customer_ID' in df_cc.\n",
      "Columns in df_demog: ['ID', 'account_type', 'gender', 'age', 'Income', 'Emp_Tenure_Years', 'Tenure_with_Bank', 'region_code', 'NetBanking_Flag', 'Avg_days_between_transaction']\n",
      "Renamed 'ID' to 'Customer_ID' in df_demog.\n",
      "Columns in df_behavior: ['ID', 'cc_cons_apr', 'dc_cons_apr', 'cc_cons_may', 'dc_cons_may', 'cc_cons_jun', 'dc_cons_jun', 'cc_count_apr', 'cc_count_may', 'cc_count_jun', 'dc_count_apr', 'dc_count_may', 'dc_count_jun', 'card_lim', 'personal_loan_active', 'vehicle_loan_active', 'personal_loan_closed', 'vehicle_loan_closed', 'investment_1', 'investment_2', 'investment_3', 'investment_4', 'debit_amount_apr', 'credit_amount_apr', 'debit_count_apr', 'credit_count_apr', 'max_credit_amount_apr', 'debit_amount_may', 'credit_amount_may', 'credit_count_may', 'debit_count_may', 'max_credit_amount_may', 'debit_amount_jun', 'credit_amount_jun', 'credit_count_jun', 'debit_count_jun', 'max_credit_amount_jun', 'loan_enq', 'emi_active']\n",
      "Renamed 'ID' to 'Customer_ID' in df_behavior.\n",
      "Data loaded and merged successfully. Initial shape: (20000, 49)\n",
      "Columns: ['Customer_ID', 'cc_cons', 'account_type', 'gender', 'age', 'Income', 'Emp_Tenure_Years', 'Tenure_with_Bank', 'region_code', 'NetBanking_Flag', 'Avg_days_between_transaction', 'cc_cons_apr', 'dc_cons_apr', 'cc_cons_may', 'dc_cons_may', 'cc_cons_jun', 'dc_cons_jun', 'cc_count_apr', 'cc_count_may', 'cc_count_jun', 'dc_count_apr', 'dc_count_may', 'dc_count_jun', 'card_lim', 'personal_loan_active', 'vehicle_loan_active', 'personal_loan_closed', 'vehicle_loan_closed', 'investment_1', 'investment_2', 'investment_3', 'investment_4', 'debit_amount_apr', 'credit_amount_apr', 'debit_count_apr', 'credit_count_apr', 'max_credit_amount_apr', 'debit_amount_may', 'credit_amount_may', 'credit_count_may', 'debit_count_may', 'max_credit_amount_may', 'debit_amount_jun', 'credit_amount_jun', 'credit_count_jun', 'debit_count_jun', 'max_credit_amount_jun', 'loan_enq', 'emi_active']\n",
      "\n",
      "First 5 rows of merged data:\n",
      "   Customer_ID  cc_cons account_type gender  age  Income  Emp_Tenure_Years  \\\n",
      "0        17051  16239.0      current      M   30  MEDIUM              26.4   \n",
      "1        11491  39002.0      current      M   37     LOW              14.4   \n",
      "2         7433  21182.0      current      M   33  MEDIUM               3.2   \n",
      "3        14606   8123.0      current      M   63     LOW              10.2   \n",
      "4         8381  28282.0       saving      M   33  MEDIUM              26.4   \n",
      "\n",
      "   Tenure_with_Bank  region_code  NetBanking_Flag  ...  credit_count_may  \\\n",
      "0                 9            9              355  ...                47   \n",
      "1                 7            7              485  ...                 0   \n",
      "2                 1            1              764  ...                 2   \n",
      "3                 6            6              863  ...                45   \n",
      "4                 6            6              523  ...                 1   \n",
      "\n",
      "   debit_count_may  max_credit_amount_may  debit_amount_jun  \\\n",
      "0               20                41860.0          32734.75   \n",
      "1                8               113367.0          60974.75   \n",
      "2               14               168000.0         425802.96   \n",
      "3               44                57750.0          25537.91   \n",
      "4                2                18405.0          64687.32   \n",
      "\n",
      "   credit_amount_jun  credit_count_jun  debit_count_jun  \\\n",
      "0           80959.00                36                9   \n",
      "1          495080.00                 5                3   \n",
      "2          115707.38                 7               58   \n",
      "3           63606.00                12                0   \n",
      "4           62353.35                49               35   \n",
      "\n",
      "   max_credit_amount_jun  loan_enq  emi_active  \n",
      "0               171200.0         Y     3448.84  \n",
      "1                15694.0         Y     3812.69  \n",
      "2                28058.0         Y     9432.90  \n",
      "3                24459.0         Y      144.61  \n",
      "4                31574.0         Y     1887.89  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "\n",
      "Training set shape (cc_cons not missing): (15000, 49)\n",
      "Prediction set shape (cc_cons missing): (5000, 49)\n",
      "\n",
      "--- 3. Preprocessing Training Data ---\n",
      "Imputed numerical column: age\n",
      "Imputed numerical column: Emp_Tenure_Years\n",
      "Imputed numerical column: Tenure_with_Bank\n",
      "Imputed numerical column: region_code\n",
      "Imputed numerical column: NetBanking_Flag\n",
      "Imputed numerical column: Avg_days_between_transaction\n",
      "Imputed numerical column: cc_cons_apr\n",
      "Imputed numerical column: dc_cons_apr\n",
      "Imputed numerical column: cc_cons_may\n",
      "Imputed numerical column: dc_cons_may\n",
      "Imputed numerical column: cc_cons_jun\n",
      "Imputed numerical column: dc_cons_jun\n",
      "Imputed numerical column: cc_count_apr\n",
      "Imputed numerical column: cc_count_may\n",
      "Imputed numerical column: cc_count_jun\n",
      "Imputed numerical column: dc_count_apr\n",
      "Imputed numerical column: dc_count_may\n",
      "Imputed numerical column: dc_count_jun\n",
      "Imputed numerical column: card_lim\n",
      "Imputed numerical column: personal_loan_active\n",
      "Imputed numerical column: vehicle_loan_active\n",
      "Imputed numerical column: personal_loan_closed\n",
      "Imputed numerical column: vehicle_loan_closed\n",
      "Imputed numerical column: investment_1\n",
      "Imputed numerical column: investment_2\n",
      "Imputed numerical column: investment_3\n",
      "Imputed numerical column: investment_4\n",
      "Imputed numerical column: debit_amount_apr\n",
      "Imputed numerical column: credit_amount_apr\n",
      "Imputed numerical column: debit_count_apr\n",
      "Imputed numerical column: credit_count_apr\n",
      "Imputed numerical column: max_credit_amount_apr\n",
      "Imputed numerical column: debit_amount_may\n",
      "Imputed numerical column: credit_amount_may\n",
      "Imputed numerical column: credit_count_may\n",
      "Imputed numerical column: debit_count_may\n",
      "Imputed numerical column: max_credit_amount_may\n",
      "Imputed numerical column: debit_amount_jun\n",
      "Imputed numerical column: credit_amount_jun\n",
      "Imputed numerical column: credit_count_jun\n",
      "Imputed numerical column: debit_count_jun\n",
      "Imputed numerical column: max_credit_amount_jun\n",
      "Imputed numerical column: emi_active\n",
      "Imputed categorical column: account_type\n",
      "Imputed categorical column: gender\n",
      "Imputed categorical column: Income\n",
      "Imputed categorical column: loan_enq\n",
      "Created dummies for categorical features. New training set shape: (15000, 49)\n",
      "Columns in df_train_set_processed before dropping: ['Customer_ID', 'cc_cons', 'age', 'Emp_Tenure_Years', 'Tenure_with_Bank', 'region_code', 'NetBanking_Flag', 'Avg_days_between_transaction', 'cc_cons_apr', 'dc_cons_apr', 'cc_cons_may', 'dc_cons_may', 'cc_cons_jun', 'dc_cons_jun', 'cc_count_apr', 'cc_count_may', 'cc_count_jun', 'dc_count_apr', 'dc_count_may', 'dc_count_jun', 'card_lim', 'personal_loan_active', 'vehicle_loan_active', 'personal_loan_closed', 'vehicle_loan_closed', 'investment_1', 'investment_2', 'investment_3', 'investment_4', 'debit_amount_apr', 'credit_amount_apr', 'debit_count_apr', 'credit_count_apr', 'max_credit_amount_apr', 'debit_amount_may', 'credit_amount_may', 'credit_count_may', 'debit_count_may', 'max_credit_amount_may', 'debit_amount_jun', 'credit_amount_jun', 'credit_count_jun', 'debit_count_jun', 'max_credit_amount_jun', 'emi_active', 'account_type_saving', 'gender_M', 'Income_LOW', 'Income_MEDIUM']\n",
      "\n",
      "Training data split: X_train (11250, 47), X_val (3750, 47)\n",
      "\n",
      "--- 6. Model Training and Evaluation ---\n",
      "\n",
      "Training Linear Regression...\n",
      "  Linear Regression Evaluation:\n",
      "    Mean Absolute Error (MAE): 1857.26\n",
      "    Mean Squared Error (MSE): 6645896.59\n",
      "    Root Mean Squared Error (RMSE): 2577.96\n",
      "    R-squared (R2): 0.8660\n",
      "    Root Mean Square Percentage Error (RMSPE): 0.2703\n",
      "\n",
      "Training Random Forest Regressor...\n",
      "  Random Forest Regressor Evaluation:\n",
      "    Mean Absolute Error (MAE): 1942.74\n",
      "    Mean Squared Error (MSE): 8270621.27\n",
      "    Root Mean Squared Error (RMSE): 2875.87\n",
      "    R-squared (R2): 0.8332\n",
      "    Root Mean Square Percentage Error (RMSPE): 0.2908\n",
      "\n",
      "Training Gradient Boosting Regressor...\n",
      "  Gradient Boosting Regressor Evaluation:\n",
      "    Mean Absolute Error (MAE): 1874.71\n",
      "    Mean Squared Error (MSE): 7151315.02\n",
      "    Root Mean Squared Error (RMSE): 2674.19\n",
      "    R-squared (R2): 0.8558\n",
      "    Root Mean Square Percentage Error (RMSPE): 0.2852\n",
      "\n",
      "--- Model Comparison ---\n",
      "                                   MAE           MSE       RMSE      R2  \\\n",
      "Linear Regression            1857.2608  6.645897e+06  2577.9637  0.8660   \n",
      "Random Forest Regressor      1942.7412  8.270621e+06  2875.8688  0.8332   \n",
      "Gradient Boosting Regressor  1874.7096  7.151315e+06  2674.1943  0.8558   \n",
      "\n",
      "                              RMSPE  \n",
      "Linear Regression            0.2703  \n",
      "Random Forest Regressor      0.2908  \n",
      "Gradient Boosting Regressor  0.2852  \n",
      "\n",
      "Best performing model based on Root Mean Square Percentage Error (RMSPE): Linear Regression\n",
      "\n",
      "--- 7. Preprocessing Prediction Data ---\n",
      "Imputed numerical column in prediction set: age\n",
      "Imputed numerical column in prediction set: Emp_Tenure_Years\n",
      "Imputed numerical column in prediction set: Tenure_with_Bank\n",
      "Imputed numerical column in prediction set: region_code\n",
      "Imputed numerical column in prediction set: NetBanking_Flag\n",
      "Imputed numerical column in prediction set: Avg_days_between_transaction\n",
      "Imputed numerical column in prediction set: cc_cons_apr\n",
      "Imputed numerical column in prediction set: dc_cons_apr\n",
      "Imputed numerical column in prediction set: cc_cons_may\n",
      "Imputed numerical column in prediction set: dc_cons_may\n",
      "Imputed numerical column in prediction set: cc_cons_jun\n",
      "Imputed numerical column in prediction set: dc_cons_jun\n",
      "Imputed numerical column in prediction set: cc_count_apr\n",
      "Imputed numerical column in prediction set: cc_count_may\n",
      "Imputed numerical column in prediction set: cc_count_jun\n",
      "Imputed numerical column in prediction set: dc_count_apr\n",
      "Imputed numerical column in prediction set: dc_count_may\n",
      "Imputed numerical column in prediction set: dc_count_jun\n",
      "Imputed numerical column in prediction set: card_lim\n",
      "Imputed numerical column in prediction set: personal_loan_active\n",
      "Imputed numerical column in prediction set: vehicle_loan_active\n",
      "Imputed numerical column in prediction set: personal_loan_closed\n",
      "Imputed numerical column in prediction set: vehicle_loan_closed\n",
      "Imputed numerical column in prediction set: investment_1\n",
      "Imputed numerical column in prediction set: investment_2\n",
      "Imputed numerical column in prediction set: investment_3\n",
      "Imputed numerical column in prediction set: investment_4\n",
      "Imputed numerical column in prediction set: debit_amount_apr\n",
      "Imputed numerical column in prediction set: credit_amount_apr\n",
      "Imputed numerical column in prediction set: debit_count_apr\n",
      "Imputed numerical column in prediction set: credit_count_apr\n",
      "Imputed numerical column in prediction set: max_credit_amount_apr\n",
      "Imputed numerical column in prediction set: debit_amount_may\n",
      "Imputed numerical column in prediction set: credit_amount_may\n",
      "Imputed numerical column in prediction set: credit_count_may\n",
      "Imputed numerical column in prediction set: debit_count_may\n",
      "Imputed numerical column in prediction set: max_credit_amount_may\n",
      "Imputed numerical column in prediction set: debit_amount_jun\n",
      "Imputed numerical column in prediction set: credit_amount_jun\n",
      "Imputed numerical column in prediction set: credit_count_jun\n",
      "Imputed numerical column in prediction set: debit_count_jun\n",
      "Imputed numerical column in prediction set: max_credit_amount_jun\n",
      "Imputed numerical column in prediction set: emi_active\n",
      "Imputed categorical column in prediction set: account_type\n",
      "Imputed categorical column in prediction set: gender\n",
      "Imputed categorical column in prediction set: Income\n",
      "Imputed categorical column in prediction set: loan_enq\n",
      "Created dummies for categorical features in prediction set. New shape: (5000, 52)\n",
      "Aligned prediction set columns with training set. Final prediction set shape: (5000, 47)\n",
      "Number of columns in training features: 47\n",
      "Number of columns in prediction features: 47\n",
      "\n",
      "--- 8. Predicting Missing Credit Consumption ---\n",
      "\n",
      "Predictions for customers with initially missing 'cc_cons':\n",
      "       Customer_ID  predicted_cc_cons\n",
      "15000        17591        3182.415180\n",
      "15001        13541        6987.657522\n",
      "15002        13431        2633.896863\n",
      "15003         8687        9012.687570\n",
      "15004        14727        2655.874551\n",
      "15005        14988        8470.566787\n",
      "15006        14859       22402.759420\n",
      "15007        16636        6711.560004\n",
      "15008         7625        4000.502234\n",
      "15009        16492        3711.280349\n",
      "\n",
      "Final predicted values for customers with missing 'cc_cons' saved to: predicted_credit_consumption_for_missing.csv\n",
      "\n",
      "--- Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder # StandardScaler might be useful later\n",
    "\n",
    "# --- Utility Functions (Assuming these are already defined in your notebook) ---\n",
    "# If these are not defined, you'll need to add them here or ensure they are in a previous cell.\n",
    "\n",
    "def continuous_var_summary(x):\n",
    "    \"\"\"Generates an audit report for a continuous variable.\"\"\"\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),\n",
    "                      x.std(), x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),\n",
    "                      x.quantile(0.10), x.quantile(0.25), x.quantile(0.50), x.quantile(0.75),\n",
    "                      x.quantile(0.90), x.quantile(0.95), x.quantile(0.99), x.max()],\n",
    "                     index=['N', 'NMISS', 'SUM', 'MEAN', 'MEDIAN', 'STD', 'VAR', 'MIN', 'P1',\n",
    "                            'P5', 'P10', 'P25', 'P50', 'P75', 'P90', 'P95', 'P99', 'MAX'])\n",
    "\n",
    "def categorical_var_summary(x):\n",
    "    \"\"\"Generates an audit report for a categorical variable.\"\"\"\n",
    "    mode_val = x.mode()[0] if not x.mode().empty else np.nan\n",
    "    mode_freq = x.value_counts().max() if not x.value_counts().empty else 0\n",
    "    mode_perc = (mode_freq / x.count()) * 100 if x.count() > 0 else 0\n",
    "    return pd.Series([x.count(), x.isnull().sum(), mode_val, mode_freq, mode_perc],\n",
    "                     index=['N', 'NMISS', 'MODE', 'FREQ', 'PERCENT'])\n",
    "\n",
    "def missing_imputation(df, column_name, var_type):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a DataFrame column.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame.\n",
    "        column_name (str): The name of the column to impute.\n",
    "        var_type (str): 'continuous' or 'categorical'.\n",
    "    Returns:\n",
    "        pd.Series: The column with imputed values.\n",
    "    \"\"\"\n",
    "    if var_type == 'continuous':\n",
    "        return df[column_name].fillna(df[column_name].mean()) # Using mean for simplicity\n",
    "    elif var_type == 'categorical':\n",
    "        return df[column_name].fillna(df[column_name].mode()[0])\n",
    "    else:\n",
    "        return df[column_name] # No imputation if type is unknown\n",
    "\n",
    "def create_dummies(df, column_names):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for specified categorical columns and drops original.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame.\n",
    "        column_names (list): List of column names to convert to dummies.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with dummy variables.\n",
    "    \"\"\"\n",
    "    for col in column_names:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Square Percentage Error (RMSPE).\n",
    "    Args:\n",
    "        y_true (np.array or pd.Series): Actual values.\n",
    "        y_pred (np.array or pd.Series): Predicted values.\n",
    "    Returns:\n",
    "        float: The RMSPE value.\n",
    "    \"\"\"\n",
    "    # Avoid division by zero for y_true values close to zero\n",
    "    # Add a small epsilon to prevent division by zero for actual values that are 0\n",
    "    # Or filter out rows where y_true is 0 if that's appropriate for the business context\n",
    "    percentage_error = np.abs((y_true - y_pred) / (y_true + 1e-8)) # Add epsilon\n",
    "    return np.sqrt(np.mean(np.square(percentage_error)))\n",
    "\n",
    "\n",
    "# --- 1. Data Loading and Merging ---\n",
    "print(\"--- 1. Loading and Merging Data ---\")\n",
    "try:\n",
    "    # Corrected file paths and using pd.read_excel\n",
    "    df_cc = pd.read_excel(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\assignment\\11. Capstone Case Study - Predict Cred Card Consumption\\CreditConsumptionData.xlsx\")\n",
    "    print(f\"Columns in df_cc: {df_cc.columns.tolist()}\")\n",
    "    if 'Customer_ID' not in df_cc.columns and 'ID' in df_cc.columns:\n",
    "        df_cc.rename(columns={'ID': 'Customer_ID'}, inplace=True)\n",
    "        print(\"Renamed 'ID' to 'Customer_ID' in df_cc.\")\n",
    "    elif 'Customer_ID' not in df_cc.columns:\n",
    "        print(\"Warning: 'Customer_ID' or 'ID' not found in CreditConsumptionData.xlsx. Merge might fail.\")\n",
    "\n",
    "\n",
    "    df_demog = pd.read_excel(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\assignment\\11. Capstone Case Study - Predict Cred Card Consumption\\CustomerDemographics.xlsx\")\n",
    "    print(f\"Columns in df_demog: {df_demog.columns.tolist()}\")\n",
    "    if 'Customer_ID' not in df_demog.columns and 'ID' in df_demog.columns:\n",
    "        df_demog.rename(columns={'ID': 'Customer_ID'}, inplace=True)\n",
    "        print(\"Renamed 'ID' to 'Customer_ID' in df_demog.\")\n",
    "    elif 'Customer_ID' not in df_demog.columns:\n",
    "        print(\"Warning: 'Customer_ID' or 'ID' not found in CustomerDemographics.xlsx. Merge might fail.\")\n",
    "\n",
    "\n",
    "    df_behavior = pd.read_excel(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\assignment\\11. Capstone Case Study - Predict Cred Card Consumption\\CustomerBehaviorData.xlsx\")\n",
    "    print(f\"Columns in df_behavior: {df_behavior.columns.tolist()}\")\n",
    "    if 'Customer_ID' not in df_behavior.columns and 'ID' in df_behavior.columns:\n",
    "        df_behavior.rename(columns={'ID': 'Customer_ID'}, inplace=True)\n",
    "        print(\"Renamed 'ID' to 'Customer_ID' in df_behavior.\")\n",
    "    elif 'Customer_ID' not in df_behavior.columns:\n",
    "        print(\"Warning: 'Customer_ID' or 'ID' not found in CustomerBehaviorData.xlsx. Merge might fail.\")\n",
    "\n",
    "\n",
    "    # Merge dataframes\n",
    "    df_merged = pd.merge(df_cc, df_demog, on='Customer_ID', how='left')\n",
    "    df = pd.merge(df_merged, df_behavior, on='Customer_ID', how='left')\n",
    "\n",
    "    print(\"Data loaded and merged successfully. Initial shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of merged data:\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: One or more data files not found. Please ensure the specified paths are correct and the files exist.\")\n",
    "    print(e)\n",
    "    # Exit or handle the error appropriately if files are missing\n",
    "    exit() # Or raise an exception to stop execution\n",
    "except KeyError as e:\n",
    "    print(f\"A KeyError occurred during merging. This usually means 'Customer_ID' column is missing after initial checks. Please verify column names in your Excel files.\")\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Separate Data for Training and Prediction ---\n",
    "# Customers with non-missing 'cc_cons' for training the model\n",
    "df_train_set = df[df['cc_cons'].notna()].copy()\n",
    "\n",
    "# Customers with missing 'cc_cons' for prediction\n",
    "df_predict_set = df[df['cc_cons'].isna()].copy()\n",
    "\n",
    "print(f\"\\nTraining set shape (cc_cons not missing): {df_train_set.shape}\")\n",
    "print(f\"Prediction set shape (cc_cons missing): {df_predict_set.shape}\")\n",
    "\n",
    "# --- 3. Data Preprocessing for Training Set ---\n",
    "print(\"\\n--- 3. Preprocessing Training Data ---\")\n",
    "\n",
    "# Identify feature columns (excluding Customer_ID and cc_cons)\n",
    "# This list will contain all columns that are potential features\n",
    "all_potential_features = [col for col in df_train_set.columns if col not in ['Customer_ID', 'cc_cons']]\n",
    "\n",
    "# Separate numerical and categorical features for imputation and dummy creation\n",
    "numerical_features = df_train_set[all_potential_features].select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = df_train_set[all_potential_features].select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Explicitly remove 'Customer_ID' from categorical_features if it was mistakenly included\n",
    "# This ensures Customer_ID is never dropped by create_dummies\n",
    "if 'Customer_ID' in categorical_features:\n",
    "    categorical_features.remove('Customer_ID')\n",
    "\n",
    "# Impute missing values in the training set features\n",
    "for col in numerical_features:\n",
    "    df_train_set[col] = missing_imputation(df_train_set, col, 'continuous')\n",
    "    print(f\"Imputed numerical column: {col}\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_train_set[col] = missing_imputation(df_train_set, col, 'categorical')\n",
    "    print(f\"Imputed categorical column: {col}\")\n",
    "\n",
    "# Create dummy variables for categorical features in the training set\n",
    "df_train_set_processed = create_dummies(df_train_set, categorical_features)\n",
    "print(f\"Created dummies for categorical features. New training set shape: {df_train_set_processed.shape}\")\n",
    "\n",
    "# --- 4. Feature and Target Separation for Training ---\n",
    "# Add a diagnostic print to check columns before dropping\n",
    "print(f\"Columns in df_train_set_processed before dropping: {df_train_set_processed.columns.tolist()}\")\n",
    "\n",
    "X_train_full = df_train_set_processed.drop(['Customer_ID', 'cc_cons'], axis=1)\n",
    "y_train_full = df_train_set_processed['cc_cons']\n",
    "\n",
    "# Align columns to ensure consistency (important if some dummy columns were not created due to missing categories)\n",
    "# For now, we assume X_train_full has all necessary columns.\n",
    "\n",
    "# --- 5. Train-Validation Split ---\n",
    "# Splitting the training data further into train and validation sets for model evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining data split: X_train {X_train.shape}, X_val {X_val.shape}\")\n",
    "\n",
    "# --- 6. Model Training and Evaluation ---\n",
    "print(\"\\n--- 6. Model Training and Evaluation ---\")\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    rmspe_score = rmspe(y_val, y_pred) # Calculate RMSPE\n",
    "\n",
    "    results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'RMSPE': rmspe_score}\n",
    "\n",
    "    print(f\"  {name} Evaluation:\")\n",
    "    print(f\"    Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"    Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"    Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"    R-squared (R2): {r2:.4f}\")\n",
    "    print(f\"    Root Mean Square Percentage Error (RMSPE): {rmspe_score:.4f}\")\n",
    "\n",
    "\n",
    "# Display all results in a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Determine the best model based on R-squared (or other preferred metric, e.g., lowest RMSPE)\n",
    "# For regression, higher R2 is generally better, lower MAE/MSE/RMSE/RMSPE are better.\n",
    "# Based on the problem statement, RMSPE is the primary evaluation metric.\n",
    "best_model_name = results_df['RMSPE'].idxmin() # Select model with lowest RMSPE\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest performing model based on Root Mean Square Percentage Error (RMSPE): {best_model_name}\")\n",
    "\n",
    "# --- 7. Preprocessing for Prediction Set (for customers with missing cc_cons) ---\n",
    "print(\"\\n--- 7. Preprocessing Prediction Data ---\")\n",
    "\n",
    "# Apply the same imputation logic as used for the training set\n",
    "for col in numerical_features:\n",
    "    df_predict_set[col] = missing_imputation(df_predict_set, col, 'continuous')\n",
    "    print(f\"Imputed numerical column in prediction set: {col}\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_predict_set[col] = missing_imputation(df_predict_set, col, 'categorical')\n",
    "    print(f\"Imputed categorical column in prediction set: {col}\")\n",
    "\n",
    "# Create dummy variables for categorical features in the prediction set\n",
    "df_predict_set_processed = create_dummies(df_predict_set, categorical_features)\n",
    "print(f\"Created dummies for categorical features in prediction set. New shape: {df_predict_set_processed.shape}\")\n",
    "\n",
    "# Align columns of the prediction set with the training set features (X_train_full)\n",
    "# This is crucial to ensure the prediction set has the exact same columns in the same order.\n",
    "missing_cols_in_predict = set(X_train_full.columns) - set(df_predict_set_processed.columns)\n",
    "for c in missing_cols_in_predict:\n",
    "    df_predict_set_processed[c] = 0 # Add missing columns and fill with 0\n",
    "\n",
    "extra_cols_in_predict = set(df_predict_set_processed.columns) - set(X_train_full.columns)\n",
    "df_predict_set_processed = df_predict_set_processed.drop(columns=list(extra_cols_in_predict)) # Drop extra columns\n",
    "\n",
    "# Ensure the order of columns is identical\n",
    "X_predict = df_predict_set_processed[X_train_full.columns]\n",
    "\n",
    "print(f\"Aligned prediction set columns with training set. Final prediction set shape: {X_predict.shape}\")\n",
    "print(f\"Number of columns in training features: {len(X_train_full.columns)}\")\n",
    "print(f\"Number of columns in prediction features: {len(X_predict.columns)}\")\n",
    "# Verify that column names and order are identical\n",
    "# print(f\"Are columns identical? {list(X_train_full.columns) == list(X_predict.columns)}\")\n",
    "\n",
    "\n",
    "# --- 8. Predict Credit Consumption for Missing Values ---\n",
    "print(\"\\n--- 8. Predicting Missing Credit Consumption ---\")\n",
    "\n",
    "if not X_predict.empty:\n",
    "    predictions_for_missing = best_model.predict(X_predict)\n",
    "    df_predict_set['predicted_cc_cons'] = predictions_for_missing\n",
    "\n",
    "    print(\"\\nPredictions for customers with initially missing 'cc_cons':\")\n",
    "    print(df_predict_set[['Customer_ID', 'predicted_cc_cons']].head(10)) # Display top 10 predictions\n",
    "\n",
    "    # --- Final Output: Save Predicted Values ---\n",
    "    output_filename = 'predicted_credit_consumption_for_missing.csv'\n",
    "    df_predict_set[['Customer_ID', 'predicted_cc_cons']].to_csv(output_filename, index=False)\n",
    "    print(f\"\\nFinal predicted values for customers with missing 'cc_cons' saved to: {output_filename}\")\n",
    "else:\n",
    "    print(\"No customers with missing 'cc_cons' found to predict.\")\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e0fd1-7ba4-4ca4-ba24-417a69b6da90",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
